// Class: ReadBDT_VBF0HighVPtHighMJJ
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : BDT::BDT_VBF0HighVPtHighMJJ
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.10/09       [395785]
Creator        : ajafari
Date           : Mon Dec  3 17:56:12 2018
Host           : Linux cmsbuild49.cern.ch 2.6.32-696.10.2.el6.x86_64 #1 SMP Thu Sep 14 16:35:02 CEST 2017 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /afs/cern.ch/work/a/ajafari/Vjj/CMSSW_9_4_2/src/TopLJets2015/TopAnalysis/macro
Training events: 21675
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "False" [Print method-specific help message]
CreateMVAPdfs: "True" [Create PDFs for classifier outputs (signal and background)]
nCuts: "0" [Number of grid points in variable range used in finding optimal cut in node splitting]
BoostType: "AdaBoost" [Boosting type for the trees in the forest (note: AdaCost is still experimental)]
NegWeightTreatment: "inverseboostnegweights" [How to treat events with negative weights in the BDT training (particular the boosting) : IgnoreInTraining;  Boost With inverse boostweight; Pair events with negative and positive weights in training sample and *annihilate* them (experimental!)]
SeparationType: "giniindex" [Separation criterion for node splitting]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
NTrees: "50" [Number of trees in the forest]
MaxDepth: "3" [Max depth of the decision tree allowed]
MinNodeSize: "5%" [Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%)]
AdaBoostR2Loss: "quadratic" [Type of Loss function in AdaBoostR2]
UseBaggedBoost: "False" [Use only a random subsample of all events for growing the trees in each boost iteration.]
Shrinkage: "1.000000e+00" [Learning rate for GradBoost algorithm]
AdaBoostBeta: "6.000000e-01" [Learning rate  for AdaBoost algorithm]
UseRandomisedTrees: "False" [Determine at each node splitting the cut variable only as the best out of a random subset of variables (like in RandomForests)]
UseNvars: "4" [Size of the subset of variables used with RandomisedTree option]
UsePoissonNvars: "True" [Interpret "UseNvars" not as fixed number but as mean of a Poisson distribution in each split with RandomisedTree option]
BaggedSampleFraction: "6.000000e-01" [Relative size of bagged event sample to original size of the data sample (used whenever bagging is used (i.e. UseBaggedBoost, Bagging,)]
UseYesNoLeaf: "True" [Use Sig or Bkg categories, or the purity=S/(S+B) as classification of the leaf node -> Real-AdaBoost]
Css: "1.000000e+00" [AdaCost: cost of true signal selected signal]
Cts_sb: "1.000000e+00" [AdaCost: cost of true signal selected bkg]
Ctb_ss: "1.000000e+00" [AdaCost: cost of true bkg    selected signal]
Cbb: "1.000000e+00" [AdaCost: cost of true bkg    selected bkg ]
NodePurityLimit: "5.000000e-01" [In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise.]
RegressionLossFunctionBDTG: "huber" [Loss function for BDTG regression.]
HuberQuantile: "7.000000e-01" [In the Huber loss function this is the quantile that separates the core from the tails in the residuals distribution.]
DoBoostMonitor: "False" [Create control plot with ROC integral vs tree number]
UseFisherCuts: "False" [Use multivariate splits using the Fisher criterion]
MinLinCorrForFisher: "8.000000e-01" [The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting]
UseExclusiveVars: "False" [Variables already used in fisher criterion are not anymore analysed individually for node splitting]
DoPreselection: "False" [and and apply automatic pre-selection for 100% efficient signal (bkg) cuts prior to training]
SigToBkgFraction: "1.000000e+00" [Sig to Bkg ratio used in Training (similar to NodePurityLimit, which cannot be used in real adaboost]
PruneMethod: "nopruning" [Note: for BDTs use small trees (e.g.MaxDepth=3) and NoPruning:  Pruning: Method used for pruning (removal) of statistically insignificant branches ]
PruneStrength: "0.000000e+00" [Pruning strength]
PruningValFraction: "5.000000e-01" [Fraction of events to use for optimizing automatic pruning.]
SkipNormalization: "False" [Skip normalization at initialization, to keep expectation value of BDT output according to the fraction of events]
nEventsMin: "0" [deprecated: Use MinNodeSize (in % of training events) instead]
UseBaggedGrad: "False" [deprecated: Use *UseBaggedBoost* instead:  Use only a random subsample of all events for growing the trees in each iteration.]
GradBaggingFraction: "6.000000e-01" [deprecated: Use *BaggedSampleFraction* instead: Defines the fraction of events to be used in each iteration, e.g. when UseBaggedGrad=kTRUE. ]
UseNTrainEvents: "0" [deprecated: Use *BaggedSampleFraction* instead: Number of randomly picked training events used in randomised (and bagged) trees]
NNodesMax: "0" [deprecated: Use MaxDepth instead to limit the tree size]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 17
mjj                           mjj                           mjj                           mjj                                                             'F'    [1000.0032959,8966.10839844]
detajj                        detajj                        detajj                        detajj                                                          'F'    [0.00143074989319,7.99623584747]
dphijj                        dphijj                        dphijj                        dphijj                                                          'F'    [-3.14156651497,3.14120864868]
ystar                         ystar                         ystar                         ystar                                                           'F'    [-3.90205287933,4.21059513092]
dphibjj                       dphibjj                       dphibjj                       dphibjj                                                         'F'    [-3.14155840874,3.14158272743]
balance                       balance                       balance                       balance                                                         'F'    [0.478712558746,998.726013184]
j_c2_00[0]                    j_c2_00_0_                    j_c2_00[0]                    jet_c2_001                                                      'F'    [-1,0.64386177063]
j_c2_00[1]                    j_c2_00_1_                    j_c2_00[1]                    jet_c2_002                                                      'F'    [-1,0.648723065853]
j_qg[0]                       j_qg_0_                       j_qg[0]                       leadjet_qg                                                      'F'    [-1,1]
j_qg[1]                       j_qg_1_                       j_qg[1]                       subleadjet_qg                                                   'F'    [-1,1]
dphivj0                       dphivj0                       dphivj0                       dphivj0                                                         'F'    [0.00399923324585,3.14154934883]
dphivj1                       dphivj1                       dphivj1                       dphivj1                                                         'F'    [0.00106024742126,3.14139556885]
dphivj2                       dphivj2                       dphivj2                       dphivj2                                                         'F'    [9.10609960556e-05,9999]
dphivj3                       dphivj3                       dphivj3                       dphivj3                                                         'F'    [0.000123858451843,9999]
mht                           mht                           mht                           mht                                                             'F'    [17.1554336548,1467.25244141]
C                             C                             C                             C                                                               'F'    [0.00490315351635,0.902186214924]
D                             D                             D                             D                                                               'F'    [2.18279756249e-12,0.758191764355]
NSpec 0


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#define NN new BDT_VBF0HighVPtHighMJJNode
   
#ifndef BDT_VBF0HighVPtHighMJJNode__def
#define BDT_VBF0HighVPtHighMJJNode__def
   
class BDT_VBF0HighVPtHighMJJNode {
   
public:
   
   // constructor of an essentially "empty" node floating in space
   BDT_VBF0HighVPtHighMJJNode ( BDT_VBF0HighVPtHighMJJNode* left,BDT_VBF0HighVPtHighMJJNode* right,
                          int selector, double cutValue, bool cutType, 
                          int nodeType, double purity, double response ) :
   fLeft         ( left         ),
   fRight        ( right        ),
   fSelector     ( selector     ),
   fCutValue     ( cutValue     ),
   fCutType      ( cutType      ),
   fNodeType     ( nodeType     ),
   fPurity       ( purity       ),
   fResponse     ( response     ){
   }

   virtual ~BDT_VBF0HighVPtHighMJJNode();

   // test event if it descends the tree at this node to the right
   virtual bool GoesRight( const std::vector<double>& inputValues ) const;
   BDT_VBF0HighVPtHighMJJNode* GetRight( void )  {return fRight; };

   // test event if it descends the tree at this node to the left 
   virtual bool GoesLeft ( const std::vector<double>& inputValues ) const;
   BDT_VBF0HighVPtHighMJJNode* GetLeft( void ) { return fLeft; };   

   // return  S/(S+B) (purity) at this node (from  training)

   double GetPurity( void ) const { return fPurity; } 
   // return the node type
   int    GetNodeType( void ) const { return fNodeType; }
   double GetResponse(void) const {return fResponse;}

private:

   BDT_VBF0HighVPtHighMJJNode*   fLeft;     // pointer to the left daughter node
   BDT_VBF0HighVPtHighMJJNode*   fRight;    // pointer to the right daughter node
   int                     fSelector; // index of variable used in node selection (decision tree)   
   double                  fCutValue; // cut value applied on this node to discriminate bkg against sig
   bool                    fCutType;  // true: if event variable > cutValue ==> signal , false otherwise
   int                     fNodeType; // Type of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal 
   double                  fPurity;   // Purity of node from training
   double                  fResponse; // Regression response value of node
}; 
   
//_______________________________________________________________________
   BDT_VBF0HighVPtHighMJJNode::~BDT_VBF0HighVPtHighMJJNode()
{
   if (fLeft  != NULL) delete fLeft;
   if (fRight != NULL) delete fRight;
}; 
   
//_______________________________________________________________________
bool BDT_VBF0HighVPtHighMJJNode::GoesRight( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the right
   bool result;
     result = (inputValues[fSelector] > fCutValue );
   if (fCutType == true) return result; //the cuts are selecting Signal ;
   else return !result;
}
   
//_______________________________________________________________________
bool BDT_VBF0HighVPtHighMJJNode::GoesLeft( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the left
   if (!this->GoesRight(inputValues)) return true;
   else return false;
}
   
#endif
   
#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadBDT_VBF0HighVPtHighMJJ : public IClassifierReader {

 public:

   // constructor
   ReadBDT_VBF0HighVPtHighMJJ( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadBDT_VBF0HighVPtHighMJJ" ),
        fNvars( 17 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "mjj", "detajj", "dphijj", "ystar", "dphibjj", "balance", "j_c2_00[0]", "j_c2_00[1]", "j_qg[0]", "j_qg[1]", "dphivj0", "dphivj1", "dphivj2", "dphivj3", "mht", "C", "D" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;
      fVmin[3] = 0;
      fVmax[3] = 0;
      fVmin[4] = 0;
      fVmax[4] = 0;
      fVmin[5] = 0;
      fVmax[5] = 0;
      fVmin[6] = 0;
      fVmax[6] = 0;
      fVmin[7] = 0;
      fVmax[7] = 0;
      fVmin[8] = 0;
      fVmax[8] = 0;
      fVmin[9] = 0;
      fVmax[9] = 0;
      fVmin[10] = 0;
      fVmax[10] = 0;
      fVmin[11] = 0;
      fVmax[11] = 0;
      fVmin[12] = 0;
      fVmax[12] = 0;
      fVmin[13] = 0;
      fVmax[13] = 0;
      fVmin[14] = 0;
      fVmax[14] = 0;
      fVmin[15] = 0;
      fVmax[15] = 0;
      fVmin[16] = 0;
      fVmax[16] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';
      fType[13] = 'F';
      fType[14] = 'F';
      fType[15] = 'F';
      fType[16] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadBDT_VBF0HighVPtHighMJJ() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[17];
   double fVmax[17];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[17];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   std::vector<BDT_VBF0HighVPtHighMJJNode*> fForest;       // i.e. root nodes of decision trees
   std::vector<double>                fBoostWeights; // the weights applied in the individual boosts
};

double ReadBDT_VBF0HighVPtHighMJJ::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   double myMVA = 0;
   double norm  = 0;
   for (unsigned int itree=0; itree<fForest.size(); itree++){
      BDT_VBF0HighVPtHighMJJNode *current = fForest[itree];
      while (current->GetNodeType() == 0) { //intermediate node
         if (current->GoesRight(inputValues)) current=(BDT_VBF0HighVPtHighMJJNode*)current->GetRight();
         else current=(BDT_VBF0HighVPtHighMJJNode*)current->GetLeft();
      }
      myMVA += fBoostWeights[itree] *  current->GetNodeType();
      norm  += fBoostWeights[itree];
   }
   return myMVA /= norm;
};

void ReadBDT_VBF0HighVPtHighMJJ::Initialize()
{
  // itree = 0
  fBoostWeights.push_back(0.325764922397173);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 3.12639, 0, 1, 0.602884,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.283423,-99) , 
3, 1.53564, 1, 0, 0.56036,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.545447,-99) , 
NN(
0, 
0, 
-1, 3.00186, 0, -1, 0.3008,-99) , 
0, 1666.81, 0, 0, 0.349492,-99) , 
6, 0.573214, 1, 0, 0.5,-99)    );
  // itree = 1
  fBoostWeights.push_back(0.30571);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.81057,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.594102,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.409256,-99) , 
3, -0.926826, 0, 0, 0.54781,-99) , 
0, 2144.99, 0, 0, 0.580782,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.538822,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.325638,-99) , 
3, -0.83188, 0, 0, 0.475315,-99) , 
NN(
0, 
0, 
-1, 3.1107, 0, -1, 0.335439,-99) , 
0, 1424.18, 0, 0, 0.39592,-99) , 
12, 3.00331, 0, 0, 0.472713,-99)    );
  // itree = 2
  fBoostWeights.push_back(0.223441);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 1695.42, 0, 1, 0.558046,-99) , 
NN(
0, 
0, 
-1, 2.83509, 1, -1, 0.357154,-99) , 
3, 1.27063, 1, 0, 0.521496,-99) , 
NN(
0, 
0, 
-1, 0.835513, 0, -1, 0.363745,-99) , 
13, 3.13183, 0, 0, 0.474846,-99)    );
  // itree = 3
  fBoostWeights.push_back(0.245543);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.57325,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.386799,-99) , 
3, -1.38138, 0, 0, 0.542909,-99) , 
NN(
0, 
0, 
-1, 2.43676, 0, -1, 0.402607,-99) , 
7, 0.550123, 1, 0, 0.490743,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.293367,-99) , 
8, 0.0943848, 0, 0, 0.466802,-99)    );
  // itree = 4
  fBoostWeights.push_back(0.210317);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.638863,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.548839,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.420825,-99) , 
8, 0.815643, 0, 0, 0.490832,-99) , 
NN(
0, 
0, 
-1, 1.82578, 1, -1, 0.381248,-99) , 
3, 0.658804, 1, 0, 0.454555,-99) , 
0, 2239.52, 0, 0, 0.472342,-99)    );
  // itree = 5
  fBoostWeights.push_back(0.224407);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.577688,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.349904,-99) , 
3, -1.55144, 0, 0, 0.542793,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.355485,-99) , 
3, 1.56577, 1, 0, 0.51628,-99) , 
NN(
0, 
0, 
-1, 0.543273, 0, -1, 0.415431,-99) , 
1, 2.89471, 0, 0, 0.480929,-99)    );
  // itree = 6
  fBoostWeights.push_back(0.139648);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.45714, 1, 1, 0.541373,-99) , 
NN(
0, 
0, 
-1, 91.7713, 1, -1, 0.453612,-99) , 
9, 0.404046, 0, 0, 0.516281,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.538563,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.439448,-99) , 
6, 0.504845, 1, 0, 0.469705,-99) , 
NN(
0, 
0, 
-1, 1430.24, 0, -1, 0.350685,-99) , 
11, 1.72493, 1, 0, 0.433352,-99) , 
10, 2.89675, 1, 0, 0.485088,-99)    );
  // itree = 7
  fBoostWeights.push_back(0.088535);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.660555,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.505096,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.441854,-99) , 
15, 0.253467, 0, 0, 0.485177,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.359038,-99) , 
8, 0.0482821, 0, 0, 0.475452,-99) , 
0, 2637.49, 0, 0, 0.483784,-99)    );
  // itree = 8
  fBoostWeights.push_back(0.126085);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.640365,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.526028,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.444268,-99) , 
3, 0.510285, 1, 0, 0.494905,-99) , 
NN(
0, 
0, 
-1, 1.00184, 0, -1, 0.438135,-99) , 
5, 73.0768, 1, 0, 0.469659,-99) , 
0, 2637.49, 0, 0, 0.477256,-99)    );
  // itree = 9
  fBoostWeights.push_back(0.112197);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.62497,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.523385,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.458981,-99) , 
2, 1.39242, 0, 0, 0.484305,-99) , 
0, 2365.82, 0, 0, 0.494446,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.384665,-99) , 
8, 0.0524968, 0, 0, 0.485662,-99)    );
  // itree = 10
  fBoostWeights.push_back(0.097967);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.635088,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.445314,-99) , 
0, 1296.23, 0, 0, 0.568102,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.505399,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.439999,-99) , 
3, -0.914353, 0, 0, 0.488809,-99) , 
6, 0.458139, 1, 0, 0.502609,-99) , 
NN(
0, 
0, 
-1, 55.0795, 0, -1, 0.416481,-99) , 
0, 1065.66, 0, 0, 0.49162,-99)    );
  // itree = 11
  fBoostWeights.push_back(0.0928865);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 1629.39, 0, 1, 0.567336,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.551789,-99) , 
NN(
0, 
0, 
-1, 2.98488, 1, -1, 0.466694,-99) , 
9, 0.99734, 0, 0, 0.475037,-99) , 
6, 0.430362, 1, 0, 0.485085,-99)    );
  // itree = 12
  fBoostWeights.push_back(0.0872009);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.612333,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.497796,-99) , 
0, 1695.42, 0, 0, 0.531677,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.500444,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.407724,-99) , 
0, 1460.56, 1, 0, 0.471801,-99) , 
1, 3.12075, 0, 0, 0.506628,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.416884,-99) , 
3, 1.85879, 1, 0, 0.499593,-99)    );
  // itree = 13
  fBoostWeights.push_back(0.145217);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.000191927, 1, 1, 0.554197,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.575414,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.392621,-99) , 
11, 0.582343, 1, 0, 0.460815,-99) , 
10, 2.98488, 1, 0, 0.527228,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.544667,-99) , 
NN(
0, 
0, 
-1, 0.320888, 0, -1, 0.446351,-99) , 
1, 0.957346, 1, 0, 0.468088,-99) , 
1, 3.12075, 0, 0, 0.503085,-99)    );
  // itree = 14
  fBoostWeights.push_back(0.0629311);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.573612,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.648388,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.490336,-99) , 
0, 2798.73, 0, 0, 0.495378,-99) , 
6, 0.589442, 0, 0, 0.504946,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.41902,-99) , 
8, 0.0544074, 0, 0, 0.497987,-99)    );
  // itree = 15
  fBoostWeights.push_back(0.0760285);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.593261,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.537685,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.488142,-99) , 
12, 2.9814, 0, 0, 0.509354,-99) , 
14, 483.635, 0, 0, 0.516213,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.434521,-99) , 
8, 0.0544074, 0, 0, 0.509621,-99)    );
  // itree = 16
  fBoostWeights.push_back(0.0970563);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, -0.528639, 0, 1, 0.540558,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.552192,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.470607,-99) , 
16, 0.020092, 0, 0, 0.493632,-99) , 
3, 0.248059, 1, 0, 0.518188,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.432499,-99) , 
3, -1.86549, 0, 0, 0.512173,-99)    );
  // itree = 17
  fBoostWeights.push_back(0.0925639);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.602072,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.551636,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.493634,-99) , 
3, 0.248059, 1, 0, 0.513171,-99) , 
6, 0.430362, 1, 0, 0.522839,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.556056,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.45827,-99) , 
12, 2.77957, 0, 0, 0.50307,-99) , 
NN(
0, 
0, 
-1, 0.281257, 0, -1, 0.435885,-99) , 
10, 2.86932, 1, 0, 0.474188,-99) , 
3, -0.640364, 0, 0, 0.50685,-99)    );
  // itree = 18
  fBoostWeights.push_back(0.084577);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.649782,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.474517,-99) , 
10, 3.04326, 1, 0, 0.575892,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.575828,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.512546,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.463411,-99) , 
10, 2.84974, 1, 0, 0.496208,-99) , 
11, 0.383573, 1, 0, 0.504718,-99) , 
16, 0.000204964, 1, 0, 0.513481,-99)    );
  // itree = 19
  fBoostWeights.push_back(0.115176);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.551409,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.464317,-99) , 
3, 1.86822, 1, 0, 0.53863,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.554407,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.465207,-99) , 
15, 0.443844, 0, 0, 0.4853,-99) , 
3, -0.532908, 0, 0, 0.518905,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.518702,-99) , 
NN(
0, 
0, 
-1, 0.60884, 1, -1, 0.421755,-99) , 
8, 0.964831, 0, 0, 0.456896,-99) , 
16, 0.0375287, 1, 0, 0.505641,-99)    );
  // itree = 20
  fBoostWeights.push_back(0.0702783);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.630066,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.48971,-99) , 
10, 3.05049, 1, 0, 0.572662,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.575199,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.495632,-99) , 
9, 0.596238, 1, 0, 0.505073,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.504727,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.401736,-99) , 
11, 1.81303, 1, 0, 0.461175,-99) , 
9, 0.40673, 0, 0, 0.492148,-99) , 
16, 0.000204964, 1, 0, 0.501969,-99)    );
  // itree = 21
  fBoostWeights.push_back(0.0752388);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.271498, 1, 1, 0.525925,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.445585,-99) , 
6, 0.609749, 1, 0, 0.518919,-99) , 
NN(
0, 
0, 
-1, 2.75144, 1, -1, 0.451054,-99) , 
7, 0.59027, 1, 0, 0.509338,-99)    );
  // itree = 22
  fBoostWeights.push_back(0.0780537);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 2157.87, 0, 1, 0.557599,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.517613,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.456571,-99) , 
7, 0.447199, 0, 0, 0.504547,-99) , 
NN(
0, 
0, 
-1, 2.82825, 1, -1, 0.456886,-99) , 
9, 0.40673, 0, 0, 0.490537,-99) , 
16, 0.000204964, 1, 0, 0.498668,-99)    );
  // itree = 23
  fBoostWeights.push_back(0.0805209);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.558183,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.567701,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.48255,-99) , 
2, -1.32451, 1, 0, 0.512606,-99) , 
NN(
0, 
0, 
-1, -2.73591, 0, -1, 0.471367,-99) , 
16, 0.00434076, 1, 0, 0.489219,-99) , 
7, 0.403052, 1, 0, 0.494459,-99)    );
  // itree = 24
  fBoostWeights.push_back(0.0684644);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.559602,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.516422,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.449578,-99) , 
8, 0.997744, 1, 0, 0.507063,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.434395,-99) , 
5, 196.537, 1, 0, 0.500405,-99) , 
14, 465.513, 0, 0, 0.505994,-99)    );
  // itree = 25
  fBoostWeights.push_back(0.0859861);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.53502,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.482576,-99) , 
14, 259.078, 0, 0, 0.511366,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.532811,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.426653,-99) , 
9, 0.957652, 0, 0, 0.465731,-99) , 
16, 0.0375287, 1, 0, 0.502148,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.503534,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.394923,-99) , 
5, 55.0795, 0, 0, 0.452133,-99) , 
0, 1065.66, 0, 0, 0.495676,-99)    );
  // itree = 26
  fBoostWeights.push_back(0.0648984);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.628107,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.496445,-99) , 
0, 1584.23, 0, 0, 0.540767,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.50945,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460464,-99) , 
14, 331.007, 1, 0, 0.493558,-99) , 
6, 0.458139, 1, 0, 0.501679,-99) , 
NN(
0, 
0, 
-1, -0.0110617, 0, -1, 0.450852,-99) , 
0, 1065.66, 0, 0, 0.495111,-99)    );
  // itree = 27
  fBoostWeights.push_back(0.0659387);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.544572,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.566362,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.466839,-99) , 
0, 1296.23, 0, 0, 0.52228,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.500127,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.461192,-99) , 
16, 0.00661258, 1, 0, 0.480656,-99) , 
6, 0.464377, 1, 0, 0.488663,-99) , 
14, 465.513, 0, 0, 0.493942,-99)    );
  // itree = 28
  fBoostWeights.push_back(0.0534635);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.593635,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.480316,-99) , 
9, 0.761309, 0, 0, 0.53562,-99) , 
NN(
0, 
0, 
-1, 0.997825, 1, -1, 0.488268,-99) , 
6, 0.458139, 1, 0, 0.496151,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.4245,-99) , 
15, 0.0886517, 0, 0, 0.492091,-99)    );
  // itree = 29
  fBoostWeights.push_back(0.0533229);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.559857,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.509854,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.446659,-99) , 
0, 1965.86, 1, 0, 0.501726,-99) , 
16, 0.000204964, 1, 0, 0.507424,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.437651,-99) , 
15, 0.0886517, 0, 0, 0.503482,-99)    );
  // itree = 30
  fBoostWeights.push_back(0.0952328);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.565403,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.479321,-99) , 
3, -0.46774, 0, 0, 0.531991,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.55804,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.474389,-99) , 
5, 24.7011, 1, 0, 0.486941,-99) , 
7, 0.556176, 0, 0, 0.501318,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.519674,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.411227,-99) , 
15, 0.38783, 0, 0, 0.460649,-99) , 
2, -2.74415, 0, 0, 0.494577,-99)    );
  // itree = 31
  fBoostWeights.push_back(0.0676876);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.578207,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511081,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.438544,-99) , 
13, 2.169, 0, 0, 0.50468,-99) , 
13, 1.33474, 1, 0, 0.511078,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.538639,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.421628,-99) , 
4, -2.71922, 1, 0, 0.462617,-99) , 
2, -2.74415, 0, 0, 0.503059,-99)    );
  // itree = 32
  fBoostWeights.push_back(0.0955863);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, -2.92013, 1, 1, 0.518963,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.429502,-99) , 
4, -3.02575, 0, 0, 0.507133,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.565711,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.466592,-99) , 
5, 37.9403, 1, 0, 0.525655,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.528845,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.437091,-99) , 
9, 0.993621, 0, 0, 0.449814,-99) , 
14, 244.171, 1, 0, 0.474034,-99) , 
5, 57.9332, 0, 0, 0.492048,-99)    );
  // itree = 33
  fBoostWeights.push_back(0.0778618);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.571349,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.540169,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.475553,-99) , 
6, 0.580725, 0, 0, 0.486147,-99) , 
0, 2363.08, 0, 0, 0.491851,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.446887,-99) , 
8, 0.0776546, 0, 0, 0.487174,-99)    );
  // itree = 34
  fBoostWeights.push_back(0.0607835);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.566139,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.477579,-99) , 
0, 1296.23, 0, 0, 0.527524,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.548344,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.489659,-99) , 
4, -3.07864, 1, 0, 0.498636,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.429616,-99) , 
8, 0.997825, 1, 0, 0.492928,-99) , 
6, 0.459739, 1, 0, 0.499034,-99)    );
  // itree = 35
  fBoostWeights.push_back(0.0723555);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 464.836, 0, 1, 0.521286,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.524664,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.413114,-99) , 
10, 2.8529, 1, 0, 0.458347,-99) , 
4, -3.09914, 0, 0, 0.513336,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.540842,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.447441,-99) , 
4, -2.71922, 1, 0, 0.480238,-99) , 
2, -2.73591, 0, 0, 0.507744,-99)    );
  // itree = 36
  fBoostWeights.push_back(0.0617793);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.556165,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.476708,-99) , 
0, 1611.47, 1, 0, 0.530895,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.590985,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.491283,-99) , 
14, 467.998, 0, 0, 0.499845,-99) , 
NN(
0, 
0, 
-1, 1508.89, 1, -1, 0.448939,-99) , 
11, 0.767952, 0, 0, 0.490194,-99) , 
11, 0.403015, 1, 0, 0.495882,-99)    );
  // itree = 37
  fBoostWeights.push_back(0.0530618);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.588111,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.554616,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.497989,-99) , 
14, 409.797, 0, 0, 0.506806,-99) , 
2, 2.46089, 0, 0, 0.512653,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.530003,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.430101,-99) , 
0, 1382.5, 1, 0, 0.47948,-99) , 
2, 2.68707, 1, 0, 0.506582,-99)    );
  // itree = 38
  fBoostWeights.push_back(0.0950185);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.592968,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.469285,-99) , 
3, 0.851876, 1, 0, 0.554474,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.521428,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.444102,-99) , 
1, 4.44911, 1, 0, 0.509159,-99) , 
0, 1668.94, 0, 0, 0.520219,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.533676,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.448609,-99) , 
5, 60.0624, 1, 0, 0.479599,-99) , 
2, 2.68707, 1, 0, 0.512796,-99)    );
  // itree = 39
  fBoostWeights.push_back(0.098845);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.573111,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.52498,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.454256,-99) , 
1, 3.10356, 0, 0, 0.501924,-99) , 
0, 1361.87, 1, 0, 0.513735,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.567046,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.491207,-99) , 
12, 1.69783, 0, 0, 0.519469,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.519138,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.416025,-99) , 
9, 0.853923, 0, 0, 0.463678,-99) , 
12, 2.40885, 1, 0, 0.486165,-99) , 
0, 1263.68, 0, 0, 0.502188,-99)    );
  // itree = 40
  fBoostWeights.push_back(0.08185);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 196.813, 1, 1, 0.568066,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.444696,-99) , 
15, 0.291761, 0, 0, 0.52418,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511818,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.46427,-99) , 
4, 3.03969, 1, 0, 0.499895,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.539791,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.413032,-99) , 
11, 2.03458, 0, 0, 0.447318,-99) , 
14, 397.687, 1, 0, 0.491026,-99) , 
5, 132.472, 0, 0, 0.497185,-99)    );
  // itree = 41
  fBoostWeights.push_back(0.1124);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.000400692, 1, 1, 0.545322,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.524691,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.432107,-99) , 
4, 3.02454, 1, 0, 0.484457,-99) , 
12, 3.0019, 0, 0, 0.509915,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.549522,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460345,-99) , 
15, 0.396135, 0, 0, 0.49953,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.509481,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.427373,-99) , 
2, -1.97205, 1, 0, 0.453268,-99) , 
12, 2.54844, 1, 0, 0.474458,-99) , 
4, 2.56407, 0, 0, 0.490465,-99)    );
  // itree = 42
  fBoostWeights.push_back(0.0607364);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.554389,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.593087,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.489821,-99) , 
0, 2157.72, 0, 0, 0.498919,-99) , 
NN(
0, 
0, 
-1, 1.32692, 0, -1, 0.469097,-99) , 
8, 0.852732, 0, 0, 0.4848,-99) , 
4, 3.1251, 0, 0, 0.488098,-99)    );
  // itree = 43
  fBoostWeights.push_back(0.0464055);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.573544,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.496214,-99) , 
5, 180.43, 1, 0, 0.526639,-99) , 
NN(
NN(
0, 
0, 
-1, 2.92413, 1, 1, 0.543606,-99) , 
NN(
0, 
0, 
-1, 2449.23, 1, -1, 0.48736,-99) , 
16, 0.000205239, 1, 0, 0.494568,-99) , 
5, 132.472, 0, 0, 0.500529,-99)    );
  // itree = 44
  fBoostWeights.push_back(0.0508095);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0.59239, 1, 1, 0.538993,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.555775,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.50838,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.463362,-99) , 
10, 2.55862, 0, 0, 0.498183,-99) , 
10, 2.12335, 1, 0, 0.503331,-99) , 
9, 0.161271, 1, 0, 0.508039,-99)    );
  // itree = 45
  fBoostWeights.push_back(0.076824);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.346573, 0, 1, 0.555515,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.546174,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.447062,-99) , 
10, 2.49999, 1, 0, 0.478689,-99) , 
9, 0.813346, 1, 0, 0.517177,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.507669,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.435521,-99) , 
10, 2.19247, 0, 0, 0.499623,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.413581,-99) , 
1, 4.82513, 1, 0, 0.491093,-99) , 
14, 244.161, 1, 0, 0.49989,-99)    );
  // itree = 46
  fBoostWeights.push_back(0.0947383);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.586361,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.521175,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.447188,-99) , 
11, 1.11112, 0, 0, 0.493888,-99) , 
10, 2.96349, 0, 0, 0.511083,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.512714,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.456085,-99) , 
16, 0.0329796, 1, 0, 0.493786,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.536656,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.411477,-99) , 
9, 0.956336, 0, 0, 0.442036,-99) , 
10, 2.98708, 1, 0, 0.47953,-99) , 
14, 244.161, 1, 0, 0.490155,-99)    );
  // itree = 47
  fBoostWeights.push_back(0.106772);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.624981,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.574804,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.459214,-99) , 
3, 0.759985, 0, 0, 0.486586,-99) , 
0, 1654.39, 0, 0, 0.505928,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.574899,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.474697,-99) , 
14, 189.279, 1, 0, 0.48236,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.417367,-99) , 
8, 0.119984, 0, 0, 0.473984,-99) , 
16, 0.0145164, 0, 0, 0.485376,-99)    );
  // itree = 48
  fBoostWeights.push_back(0.0709994);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.571276,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.46551,-99) , 
11, 0.793195, 0, 0, 0.5364,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.527523,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.482405,-99) , 
12, 2.06896, 1, 0, 0.499228,-99) , 
5, 30.695, 1, 0, 0.506573,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460403,-99) , 
3, -1.86549, 0, 0, 0.503279,-99)    );
  // itree = 49
  fBoostWeights.push_back(0.0609922);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.533399,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.499178,-99) , 
3, 0.202967, 1, 0, 0.517417,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.46139,-99) , 
0, 1046.17, 0, 0, 0.511976,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.531833,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.413326,-99) , 
0, 1404.36, 1, 0, 0.474168,-99) , 
12, 0.885896, 0, 0, 0.506827,-99)    );
   return;
};
 
// Clean up
inline void ReadBDT_VBF0HighVPtHighMJJ::Clear() 
{
   for (unsigned int itree=0; itree<fForest.size(); itree++) { 
      delete fForest[itree]; 
   }
}
   inline double ReadBDT_VBF0HighVPtHighMJJ::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            iV.reserve(inputValues.size());
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            retval = GetMvaValue__( iV );
         }
         else {
            retval = GetMvaValue__( inputValues );
         }
      }

      return retval;
   }
